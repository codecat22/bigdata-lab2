{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277ee6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b51b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants from lab1\r\n",
    "cwd = os.getcwd()\r\n",
    "\r\n",
    "train_data_path = cwd + '/prop_data/train.csv'\r\n",
    "test_data_path = cwd + '/prop_data/test.csv'\r\n",
    "evaluation_data_path = cwd + '/prop_data/evaluation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb89c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from lab1\r\n",
    "df_train  = pd.read_csv(train_data_path)\r\n",
    "df_test  = pd.read_csv(test_data_path)\r\n",
    "df_evaluation  = pd.read_csv(evaluation_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db47b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                               text\n",
      "0         0  overgeneralized, not helpful to anyone serious...\n",
      "1         1                           Great sound and service.\n",
      "2         1  love this book!!!: this book is a fast read ab...\n",
      "3         1  A hugely enjoyable screen version of Rona Jaff...\n",
      "4         0  What an uninteresting hodge-podge. It could ha...\n",
      "5         1  @USAirways customer service at its best! Rache...\n",
      "6         0  @VirginAmerica Is it normal to receive no repl...\n",
      "7         0  Imagine the worst skits from Saturday Night Li...\n",
      "8         0  This is one of the worst films ever. I like ch...\n",
      "9         1  @JetBlue flight attendant Wendi on Flt 127 on ...\n",
      "10        0  This film stars, among others, \"SlapChop\" Vinc...\n",
      "11        0  @united This isn't a one time thing either! It...\n",
      "12        1  It seems a lot of IMDB comments on this film a...\n",
      "13        1  I always wondered what happened with that magi...\n",
      "14        1  eye opening: when i think of poetry i put roet...\n",
      "15        0  Mercy the movie, actually starts out as a some...\n",
      "16        1  I like the good and evil battle. I liked Eddie...\n",
      "17        1  Unlike the previous poster, I liked the cellul...\n",
      "18        1  I was looking for this headset for a long time...\n",
      "19        0  @united mobile apps need construction from the...\n",
      "20        1  @united please give special thanks to Aaron in...\n",
      "21        1  I am appalled and dismayed that the Network ha...\n",
      "22        1  Phone now holds charge like it did when it was...\n",
      "23        1  I was never a big fan of television until I wa...\n",
      "24        0  awful product!: don't buy the badgemaker or th...\n",
      "25        0  Let me state this right from the start. I do N...\n",
      "26        1  @JetBlue it's been a while since I've angry tw...\n",
      "27        1           @VirginAmerica got it. All set - Thanks!\n",
      "28        1  astonishingly bright and easy to operate: i us...\n",
      "29        1                             Exactly what I wanted.\n",
      "...     ...                                                ...\n",
      "7470      0  original version is amazing, but disney is cra...\n",
      "7471      0  Starts really well, nice intro and build up fo...\n",
      "7472      1  Chucky's back...and it's about time! This time...\n",
      "7473      1                        The reception is excellent!\n",
      "7474      1                          @JetBlue awesome, thanks!\n",
      "7475      1  fascinating book: it has been a couple of year...\n",
      "7476      0  @AmericanAir @cheerUPDATES So you're saying th...\n",
      "7477      1  This is a Laurel & Hardy comedy short with som...\n",
      "7478      1                  Excellent wallet type phone case.\n",
      "7479      1  @USAirways YOU ARE THE BEST!!! FOLLOW ME PLEAS...\n",
      "7480      0  There are places for political commentary in f...\n",
      "7481      1  good product for reasonable price: needed a la...\n",
      "7482      0  in effective bread slicer: the product looks g...\n",
      "7483      1  @SouthwestAir in flight wifi + @TMobile wifi c...\n",
      "7484      1     Gets a signal when other Verizon phones won't.\n",
      "7485      1  funke collection: let me start by saying that ...\n",
      "7486      1  omg !!!!: i've had this book for just a few we...\n",
      "7487      1  A wonderful movie about people. I first saw Fo...\n",
      "7488      1        If you are Razr owner...you must have this!\n",
      "7489      0  doesn't work too well...: bought this because ...\n",
      "7490      0  @SouthwestAir same here. Would appreciate a fo...\n",
      "7491      0  What's the point of reviewing a movie like thi...\n",
      "7492      0  @Usairways need to learn operations. Sit a pla...\n",
      "7493      1  @JetBlue you don't need to cut services, charg...\n",
      "7494      1     @AmericanAir everything's good now brothaaaaaa\n",
      "7495      1  @USAirways YOU ARE AMAZING!!! FOLLOW ME BACK, ...\n",
      "7496      0  @JetBlue we're home, you guys recovered, now w...\n",
      "7497      1  pays for itself in 0 months: i was paying for ...\n",
      "7498      1  @AmericanAir continues to win: I've never miss...\n",
      "7499      1  Feels like an impressionistic film; if there i...\n",
      "\n",
      "[7500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c704adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                               text\n",
      "0         0  overgeneralized not helpful to anyone seriousl...\n",
      "1         1                            great sound and service\n",
      "2         1  love this book this book is a fast read about ...\n",
      "3         1  a hugely enjoyable screen version of rona jaff...\n",
      "4         0  what an uninteresting hodge podge it could hav...\n",
      "5         1  user customer service at its best rachel s too...\n",
      "6         0  user is it normal to receive no reply from cen...\n",
      "7         0  imagine the worst skits from saturday night li...\n",
      "8         0  this is one of the worst films ever i like che...\n",
      "9         1  user flight attendant wendi on flt number on n...\n",
      "10        0  this film stars among others slapchop vince of...\n",
      "11        0  user this isn t a one time thing either it s a...\n",
      "12        1  it seems a lot of imdb comments on this film a...\n",
      "13        1  i always wondered what happened with that magi...\n",
      "14        1  eye opening when i think of poetry i put roeth...\n",
      "15        0  mercy the movie actually starts out as a somew...\n",
      "16        1  i like the good and evil battle i liked eddie ...\n",
      "17        1  unlike the previous poster i liked the cellulo...\n",
      "18        1  i was looking for this headset for a long time...\n",
      "19        0  user mobile apps need construction from the gr...\n",
      "20        1  user please give special thanks to aaron in ta...\n",
      "21        1  i am appalled and dismayed that the network ha...\n",
      "22        1  phone now holds charge like it did when it was...\n",
      "23        1  i was never a big fan of television until i wa...\n",
      "24        0  awful product don t buy the badgemaker or the ...\n",
      "25        0  let me state this right from the start i do no...\n",
      "26        1  user it s been a while since i ve angry tweete...\n",
      "27        1                         user got it all set thanks\n",
      "28        1  astonishingly bright and easy to operate i use...\n",
      "29        1                              exactly what i wanted\n",
      "...     ...                                                ...\n",
      "7470      0  original version is amazing but disney is crap...\n",
      "7471      0  starts really well nice intro and build up for...\n",
      "7472      1  chucky s back and it s about time this time wi...\n",
      "7473      1                         the reception is excellent\n",
      "7474      1                                user awesome thanks\n",
      "7475      1  fascinating book it has been a couple of years...\n",
      "7476      0  user user so you re saying the call center is ...\n",
      "7477      1  this is a laurel hardy comedy short with some ...\n",
      "7478      1                   excellent wallet type phone case\n",
      "7479      1  user you are the best follow me please üôèüôèüôè‚úåÔ∏è‚úåÔ∏è...\n",
      "7480      0  there are places for political commentary in f...\n",
      "7481      1  good product for reasonable price needed a lar...\n",
      "7482      0  in effective bread slicer the product looks go...\n",
      "7483      1  user in flight wifi user wifi calling makes fo...\n",
      "7484      1      gets a signal when other verizon phones won t\n",
      "7485      1  funke collection let me start by saying that k...\n",
      "7486      1  omg i ve had this book for just a few weeks an...\n",
      "7487      1  a wonderful movie about people i first saw fou...\n",
      "7488      1           if you are razr owner you must have this\n",
      "7489      0  doesn t work too well bought this because my e...\n",
      "7490      0  user same here would appreciate a follow so i ...\n",
      "7491      0  what s the point of reviewing a movie like thi...\n",
      "7492      0  user need to learn operations sit a plane over...\n",
      "7493      1  user you don t need to cut services charge mor...\n",
      "7494      1             user everything s good now brothaaaaaa\n",
      "7495      1  user you are amazing follow me back please üôèüôèüôè...\n",
      "7496      0  user we re home you guys recovered now we can ...\n",
      "7497      1  pays for itself in number months i was paying ...\n",
      "7498      1  user continues to win i ve never missed a flig...\n",
      "7499      1  feels like an impressionistic film if there is...\n",
      "\n",
      "[7500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    " #from lab1\r\n",
    "import re\r\n",
    "import string\r\n",
    "\r\n",
    "# data preprocessing, same as lab 1\r\n",
    "def preprocess_text(text):\r\n",
    "    # replacing url-s with the word 'url'\r\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', text)\r\n",
    "    # replacing usernames-s with the word 'user'\r\n",
    "    text = re.sub('@[^\\s]+','USER', text)\r\n",
    "    # converting text to lowercase\r\n",
    "    text = text.lower()\r\n",
    "    # remove multiple spaces\r\n",
    "    text = re.sub(' +',' ', text)\r\n",
    "    # remove punctuation marks\r\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\r\n",
    "    # replacing numbers with the word 'number'\r\n",
    "    text = re.sub(r'\\w*\\d+\\w*', 'number', text)\r\n",
    "    return text.strip()\r\n",
    "\r\n",
    "tr_data = [preprocess_text(t) for t in df_train.text]\r\n",
    "test_data = [preprocess_text(t) for t in df_test.text]\r\n",
    "evaluation_data = [preprocess_text(t) for t in df_evaluation.text]\r\n",
    "\r\n",
    "#Since the preprocessing of the texts create a list of texts, we create dataframes again to fit to the rest of the code\r\n",
    "\r\n",
    "\r\n",
    "tr_data = pd.DataFrame(tr_data, columns =['text'])\r\n",
    "test_data = pd.DataFrame(test_data, columns =['text'])\r\n",
    "evaluation_data = pd.DataFrame(evaluation_data, columns =['text'])\r\n",
    "\r\n",
    "\r\n",
    "#After tr_data, test_data and evaluation_data got turned into dataframes, we take the columns of these \r\n",
    "#and add to the original dataframes, meaning they also contain their scores\r\n",
    "df_train['text'] = tr_data['text'].values\r\n",
    "df_test['text'] = test_data['text'].values\r\n",
    "df_evaluation['text'] = evaluation_data['text'].values\r\n",
    "\r\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b36a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial from https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1, with their standard values\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "# Create feature vectors\r\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\r\n",
    "                             max_df = 0.8,\r\n",
    "                             sublinear_tf = True,\r\n",
    "                             use_idf = True)\r\n",
    "\r\n",
    "train_vectors = vectorizer.fit_transform(df_train[\"text\"])\r\n",
    "test_vectors = vectorizer.transform(df_test[\"text\"])\r\n",
    "evaluation_vectors = vectorizer.transform(df_evaluation[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e349c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 12.938633s; Prediction time: 16.045002s\n",
      "positive:  {'precision': 0.856909239574816, 'recall': 0.8397435897435898, 'f1-score': 0.848239579117766, 'support': 1248}\n",
      "negative:  {'precision': 0.8433829287392326, 'recall': 0.860223642172524, 'f1-score': 0.8517200474495848, 'support': 1252}\n",
      "positive:  {'precision': 0.858540562576437, 'recall': 0.8363780778395552, 'f1-score': 0.8473144236572118, 'support': 2518}\n",
      "negative:  {'precision': 0.8382410679230468, 'recall': 0.8601933924254633, 'f1-score': 0.8490753628952078, 'support': 2482}\n"
     ]
    }
   ],
   "source": [
    "#Tutorial from https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1 also\r\n",
    "\r\n",
    "import time\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "# Perform classification with SVM, kernel=linear\r\n",
    "classifier_linear = svm.SVC(kernel='linear')\r\n",
    "t0 = time.time()\r\n",
    "classifier_linear.fit(train_vectors, df_train['score'])\r\n",
    "t1 = time.time()\r\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\r\n",
    "prediction_linear2 = classifier_linear.predict(evaluation_vectors)\r\n",
    "t2 = time.time()\r\n",
    "time_linear_train = t1-t0\r\n",
    "time_linear_predict = t2-t1\r\n",
    "# results\r\n",
    "\r\n",
    "\r\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\r\n",
    "report = classification_report(df_test['score'], prediction_linear, output_dict=True)\r\n",
    "report2 = classification_report(df_evaluation['score'], prediction_linear2, output_dict=True)\r\n",
    "print('positive: ', report['1'])\r\n",
    "print('negative: ', report['0'])\r\n",
    "\r\n",
    "print('positive: ', report2['1'])\r\n",
    "print('negative: ', report2['0'])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84237726-498e-46fd-91f7-686fd09a09c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c303d-6bb2-42bb-8c41-b4989fdbab2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
